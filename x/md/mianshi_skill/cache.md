## 热key解决方案
## 大key解决方案

### 热key问题
要是 Redis 中某个 Key 的访问 QPS 突然变得很高，那么这个 Key 所在的 Redis Server 就会有部分请求被迫排队，进而导致延迟升高，严重时还会出现超时失败的状况。这便是我们平常所说的热 Key 问题，而那些被高频率访问的 Key 就是热 Key，结果可能会导致 Redis 集群的负载不均衡，从而影响整个系统的性能。

### 解决方案

1. 第一类是在业务层进行改造，从而解决热 Key 问题的方案。
2. 第二类是对业务层透明的，云厂商提供的，Redis 附带方案

#### 业务层
- 本地缓存全量数据
    - 本地缓存全量数据对于业务层的方案，最为简单的是服务本地缓存全量数据的方案。也就是在服务的各个实例内存中，把所有数据都缓存起来。这样当请求访问时，就可以直接从服务实例的本地缓存中获取数据，而不用请求 Redis，防止发生热 Key 问题。

- 本地缓存部分数据
    1. JdHotkey。
    2. Proxy 热 Key 承载
    3. Redis 层解决方案


### 总结
- 首先是业务服务本地缓存全量数据的方案。要是数据量不大，我们可以直接在服务本地内存把所有数据都缓存起来，这样能大幅度降低热 Key 问题导致的 Redis 访问压力。
- 然后是业务服务本地只缓存热 Key 数据的方案。当服务不能缓存全部数据时，我们可以接入热 Key 探测框架，只把那些被频繁访问的热 Key 数据存到本地，节省内存之外还能保证热 Key 的快速读取。
- 之后是 Redis 读写分离架构方案。要是不想让业务层变得复杂，我们可以采取读写分离架构，给每个 Redis Server 都加上从库，让从库去应对热 Key 的高频率读取，分担压力。
- 最后是 Proxy 热 Key 承载方案。由于读写分离架构会增加 Redis 资源成本，所以在 Redis 提供了热 Key 承载方案的条件下，我们可以优先用 Proxy 热 Key 承载方案，这样既能解决热 Key 问题，又能控制成本


#### 其它
1. rocksdb这个，确实很多大公司内部都会有这种缓存方案，它是内存+磁盘的混合存储方式，主要是缓存的数据量（TB甚至PB级）比较大的时候用，起到降本的目的。
2. 这种方式，一般相同配置的机器，单机吞吐和延时不如redis。我们一般是缓存的数据量小的时候用redis，大的时候用混合存储的方式。
3. 不是替代的关系，各有各的适用场景

4. 识别出来热key以后呢，一般会用redis做二级缓存，避免全部打到单个redis server，这样可以减少redis的压力，提高系统的性能。
5. golang.org/x/sync/singleflight 这个库，是用来解决缓存穿透的问题的，它的作用是，当多个请求同时访问同一个key时，只有第一个请求会去查询数据库，其他请求会等待第一个请求查询完后，再返回结果。这样可以避免缓存穿透问题，提高系统的性能。


#### proxy方案对比与选型建议
|方案|实时性|性能上限|侵入性|适用场景|
|---|---|---|---|---|
|京东HotKey|毫秒级|37万QPS|低|高并发实时探测与推送|
|有赞TMC|秒级|10万+QPS|中|电商、本地缓存集成|
|Codis|无|依赖集群|高|Redis|集群扩展场景|


#### 本地缓存
- 简单缓存: 如果只需要简单的键值对缓存，go-cache 是一个不错的选择。
- 高性能，零 GC: 如果对性能有极高要求，且不希望 GC 影响性能，FreeCache 是一个好的选择。
- 大容量缓存: 如果需要缓存大量数据，BigCache 是一个不错的选择，它能减少 GC 压力。
- 灵活的过期策略: 如果需要更灵活的过期策略，ttlcache 提供了更多的配置选项。
- 高并发，防止缓存穿透: groupcache 适合高并发场景，并能防止缓存穿透。


#### 
- https://www.lixueduan.com/posts/go/singleflight/




### 为什么Redis的请求处理模型之所以类似于排队系统？
主要源于其单线程事件循环架构。以下是详细解释：
1. 单线程处理核心
    - 顺序执行：Redis使用单个主线程处理所有客户端请求，每个命令按接收顺序依次执行，形成天然的队列结构。
    - 原子性保障：由于无并发执行，所有操作无需加锁，天然保证原子性（如 INCR 操作不会出现竞态条件）。

2. 事件驱动与I/O多路复用
    - 非阻塞I/O：通过 epoll（Linux）、kqueue（BSD）等系统调用，同时监听多个客户端连接。
    - 事件队列：当多个客户端发送请求时，I/O多路复用技术将就绪事件（如可读、可写）放入队列，主线程按顺序处理。

3. 处理流程类比排队系统
    - 客户端请求入队： 所有到达的请求被暂存到内核的 套接字接收缓冲区，相当于排队系统中的“等待队列”。
    - 事件分发： Redis主线程通过事件循环（Event Loop）从队列中取出就绪事件，逐个处理，类似“服务窗口”逐一处理客户请求。

    - 结果返回：处理完成后，响应数据被写入客户端的 发送缓冲区，通过异步I/O返回，不会阻塞后续请求处理。

4. 性能优势与权衡
    - 低延迟：内存操作（纳秒级）远快于线程切换（微秒级），单线程避免多线程上下文切换开销。
    - 高吞吐：非阻塞I/O + 纯内存操作，单线程可轻松达到 10万+ QPS。
    - 瓶颈场景：若单命令耗时过长（如 KEYS *），会阻塞后续请求，需避免长耗时操作。

5. 后台多线程辅助
    - 异步任务：Redis 6.0+ 引入多线程处理网络I/O（读写套接字），但命令执行仍由主线程完成。
    - 持久化与删除：生成RDB快照、AOF重写、大Key删除等任务由后台线程处理，不阻塞主线程。

6. 对于需要更高吞吐量的情况，可以通过分片（sharding）将数据分布到多个Redis实例，每个实例仍然保持单线程模型，从而水平扩展性能。    
7. 总结
Redis的请求处理模型通过 单线程 + 事件驱动 实现类似排队系统的顺序处理机制，核心优势在于：

- 简单高效：无锁、无线程切换开销。
- 原子性保障：所有操作串行化，避免并发问题。
- 高吞吐低延迟：内存操作与I/O多路复用技术结合。

这种设计使Redis成为高性能缓存和实时数据处理的理想选择，但需注意避免长耗时操作阻塞主线程。


## 大key解决方案
在请求处理过程中，若涉及的键（Key）或键关联的值（Value）数据量过大，Redis 针对这个请求的 I/O 操作耗时以及整体处理时间都将显著增加。
### 大 Key 的参考标准

1. 从 Key 的数据量来说，一个 String 类型的 Key，如果它的数据量达到 5MB，我们就可以认为它是一个“大 Key”。
2. 从 Key 成员数量来看，一个 ZSET 类型的 Key，如果它包含的成员数量超过了 10,000 个，这也符合“大 Key”的定义。
3. 从 Key 的成员数据量来看，一个 Hash 类型的 Key，即使它的成员数量只有 2,000 个，但如果这些成员的 Value（值）加起来总大小超过了 100MB，那它同样可以被视为“大 Key”。

### 在实际操作中，我们主要有两种方案可供选择。

1. 第一个是数据压缩方案，通过压缩技术减少数据的体积，使其符合大 Key 的标准，从而减少对 Redis 性能的影响。
    - 基于 PB 序列化的数据压缩方案
    - 基于 LZ4 压缩算法的数据压缩方案
2. 第二个是大 Key 拆分方案，将一个大型的 Key 拆分成多个小型的 Key，这样可以分散单个 Key 对 Redis 性能的负担。
    - 解决大 Key 问题的核心思想是将大 Value 拆分成多个小 Value，然后通过某种方式将它们关联起来
    - 基于版本号机制的大 Key 拆分方案
    - 数据结构优化
    - 使用对象存储 (Object Storage)

基于版本号机制的大 Key 拆分方案
- 主要思想是将大 Value 拆分成多个小 Value，然后通过某种方式将它们关联起来
- 核心步骤如下：
    - 1. 首先，我们需要为每个大 Value 生成一个唯一的版本号，通常使用时间戳或 UUID 等方式生成。
    - 2. 接着，我们按字节大小做拆分，子 Key 拼接上版本号，避免直接覆盖之前的数据，导致脏读。。
    - 3. 然后，我们更新 Key 的元数据信息，元数据信息里记录了子 Key 信息，从而使线上生效。
    - 4. 最后，我们需要给旧子 Key 设置过期时间，而不是直接删除，避免有 Client 正在读旧子 Key 数据。
    - 5. 首先，我们需要根据查询的 Key，从 Redis 获取包含子 Key 的元数据信息。
    - 6. 接着，我们需要根据子 Key，获取各个子 Key 的数据。
    - 7. 最后，把获取的子 Key 数据拼接起来，就得到了我们需要的完整大 Key 数据 

### 五点注意事项
1. 对大Key进行拆分、对大Key进行清理、监控实例的内存水位、对过期数据进行定期清理。
2. 提前规划数据结构，从系统设计阶段开始优化数据结构，避免产生大 Key。
3. 为大 Key 设置合理的过期时间，确保无用数据及时清理。
4. 将数据分片存储到多个 Redis 实例中，避免单个实例中的大 Key 问题。
5. 避免直接删除大 Key，通过异步任务分批删除其数据，减少阻塞。通过 UNLINK 命令替代 DEL。


#### 本地缓存的问题
- 首先要解决程序启动时的效率问题。对于数据量较小的情况，我们可以直接从数据库轮询获取数据。然而，面对大量数据时，这种方法会导致启动时间过长。为了加速程序启动，我们可以采用本地文件加载和数据库轮询加载相结合的策略。
- 之后是缓存更新的问题。对于那些对实时性要求不高的场景，我们可以设定一个时间间隔，定期从数据库轮询获取更新的数据。但是，如果业务需要更高的实时性，我们可以采用 RocketMQ 广播消费的方式，以实现更快速的数据同步。
    - https://github.com/alibaba/canal
    - sqoop
- 最后，我们讨论了数据量过大的问题。当本地缓存的数据量超出单机内存的承载能力时，我们可以采用分片集群的思想，将数据分散加载到不同的服务集群中，从而降低单机内存的负担