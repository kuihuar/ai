# Redis 缓存最终一致性保证策略

## 概述

本文档说明在 `GetUser` 和 `UpdateUser` 操作中，如何通过 Redis 缓存保证数据的最终一致性。

## 架构设计

### 缓存模式：Cache-Aside（旁路缓存）

**特点**：
- 应用程序负责维护缓存和数据库的一致性
- 缓存不作为数据源，只作为性能优化手段
- 数据库是唯一真实数据源（Single Source of Truth）

### 一致性级别：最终一致性

**说明**：
- 不保证强一致性（读写操作可能短暂看到旧数据）
- 保证最终一致性（经过一段时间后，所有节点数据一致）
- 通过延迟双删机制处理并发场景下的数据不一致问题

## 实现策略

### 1. 读操作（GetUser / FindByID）

**流程**：
```
1. 先查缓存
   ├─ 缓存命中 → 检查是否为空值标记
   │   ├─ 是空值标记（__NULL__）→ 返回 NotFound（防止缓存穿透）
   │   └─ 是正常数据 → 反序列化返回
   └─ 缓存未命中 → 继续步骤 2

2. 使用分布式锁防止缓存击穿
   ├─ 获取锁成功 → 继续步骤 3
   └─ 获取锁失败 → 等待后重试查询缓存 → 仍未命中则降级到数据库

3. 查数据库
   ├─ 找到 → 序列化并写入缓存（同步写入）
   └─ 未找到 → 缓存空值标记（防止缓存穿透）→ 返回 NotFound
```

**代码位置**：`internal/data/repo_user.go::FindByID`

**关键点**：
- ✅ 缓存命中直接返回，减少数据库压力
- ✅ **缓存击穿防护**：使用分布式锁，只允许一个协程查询数据库，其他协程等待并重试查询缓存
- ✅ **缓存穿透防护**：查询不存在的数据时，缓存空值标记（`__NULL__`），避免频繁查询数据库
- ✅ 缓存错误不影响业务，降级到数据库查询

### 2. 写操作（UpdateUser / Update）

**流程**：延迟双删策略

```
1. 先删除缓存（防止更新期间有读请求命中旧缓存）
   ↓
2. 更新数据库
   ↓
3. 再次删除缓存（立即删除，处理并发场景）
   ↓
4. 延迟删除缓存（延迟 500ms，处理并发读写场景）
```

**代码位置**：`internal/data/repo_user.go::Update`

**关键点**：
- ✅ 先删缓存再更新DB，防止更新期间读请求命中旧缓存
- ✅ 更新DB后立即删除缓存，处理并发写场景
- ✅ 延迟双删（500ms后再次删除），处理并发读写场景下的数据不一致

**延迟双删的必要性**：

考虑以下并发场景：
```
时间线：
T1: 线程A 删除缓存
T2: 线程A 更新数据库（DB: 新值）
T3: 线程B 查询缓存（未命中）
T4: 线程B 查询数据库（DB: 新值）
T5: 线程B 写入缓存（缓存: 新值）✅
T6: 线程A 再次删除缓存
T7: 线程C 查询缓存（未命中）
T8: 线程C 查询数据库（DB: 新值）
T9: 线程C 写入缓存（缓存: 新值）✅
```

但如果线程B在T6之后才写入缓存：
```
时间线：
T1: 线程A 删除缓存
T2: 线程A 更新数据库（DB: 新值）
T3: 线程B 查询缓存（未命中）
T4: 线程B 查询数据库（DB: 新值）
T5: 线程A 再次删除缓存
T6: 线程B 写入缓存（缓存: 新值）✅ 但可能写入的是旧值（如果DB更新失败回滚）
T7: 延迟删除（500ms后）→ 清理可能存在的旧数据
```

### 3. 删除操作（DeleteUser / Delete）

**流程**：
```
1. 先删除缓存
   ↓
2. 删除数据库记录
   ↓
3. 再次删除缓存（确保删除）
```

**代码位置**：`internal/data/repo_user.go::Delete`

**关键点**：
- ✅ 删除时同时删除缓存，防止缓存中残留已删除的数据
- ✅ 双重删除确保缓存清理彻底

## 序列化方案

### JSON 序列化

**实现**：
- `marshalUser`: 将 `*biz.User` 序列化为 JSON 字符串
- `unmarshalUser`: 将 JSON 字符串反序列化为 `*biz.User`

**代码位置**：`internal/data/repo_user.go::marshalUser` / `unmarshalUser`

**优点**：
- ✅ 可读性好，便于调试
- ✅ 跨语言兼容
- ✅ Go 标准库支持，无需额外依赖

**缺点**：
- ⚠️ 性能略低于二进制序列化（如 Protobuf）
- ⚠️ 体积略大于二进制格式

**性能考虑**：
- 对于用户信息这种小对象，JSON 序列化性能足够
- 如果后续需要优化，可以考虑 Protobuf 或 MessagePack

## 缓存配置

### Key 格式

```
user:{id}
```

**示例**：
- `user:1` - 用户ID为1的缓存
- `user:100` - 用户ID为100的缓存

### 过期时间

```go
userCacheExpiration = 1 * time.Hour  // 1小时
```

**说明**：
- 过期时间设置为1小时，平衡缓存命中率和数据新鲜度
- 过期后自动清理，下次读取时从数据库重新加载

### 延迟双删时间

```go
userCacheDeleteDelay = 500 * time.Millisecond  // 500毫秒
```

**说明**：
- 延迟时间设置为500ms，足够处理大多数并发场景
- 可以根据实际业务场景调整（建议范围：200ms - 1s）

## 错误处理

### 缓存操作失败

**策略**：降级到数据库

**原因**：
- 缓存是性能优化手段，不是业务必需
- 缓存故障不应影响核心业务功能
- 记录警告日志，便于监控和排查

**实现**：
```go
if err != nil {
    // 缓存错误不影响业务，记录日志后继续查询数据库
    r.log.WithContext(ctx).Warnf("failed to get user from cache: %v", err)
    // 继续执行数据库查询
}
```

### 序列化失败

**策略**：降级到数据库查询

**原因**：
- 序列化失败可能是数据格式问题
- 降级到数据库查询可以获取最新数据
- 记录警告日志，便于排查问题

## 并发场景分析

### 场景1：正常读写

```
请求1: UpdateUser(id=1, nickname="新昵称")
  → 删除缓存
  → 更新DB
  → 删除缓存
  → 延迟删除缓存

请求2: GetUser(id=1) (在请求1之后)
  → 查询缓存（未命中）
  → 查询数据库（新值）
  → 写入缓存（新值）
  → 返回新值 ✅
```

**结果**：✅ 一致性保证

### 场景2：并发读写（延迟双删处理）

```
T1: 请求A UpdateUser(id=1, nickname="新昵称")
    → 删除缓存
T2: 请求B GetUser(id=1)
    → 查询缓存（未命中，因为T1已删除）
    → 查询数据库（旧值，因为T1还未更新完成）
    → 写入缓存（旧值）⚠️
T3: 请求A 更新数据库（新值）
T4: 请求A 删除缓存（清理T2写入的旧值）✅
T5: 请求A 延迟删除缓存（500ms后）
T6: 请求C GetUser(id=1) (在T5之后)
    → 查询缓存（未命中）
    → 查询数据库（新值）
    → 写入缓存（新值）✅
```

**结果**：✅ 最终一致性保证（通过延迟双删）

### 场景3：并发写

```
请求A: UpdateUser(id=1, nickname="昵称A")
请求B: UpdateUser(id=1, nickname="昵称B")

执行顺序（数据库事务保证）：
  → 请求A 删除缓存
  → 请求B 删除缓存
  → 请求A 更新DB（昵称A）
  → 请求B 更新DB（昵称B，覆盖A）
  → 请求A 删除缓存
  → 请求B 删除缓存
  → 请求A 延迟删除
  → 请求B 延迟删除

最终结果：
  → DB: 昵称B ✅
  → 缓存: 已删除，下次读取时加载昵称B ✅
```

**结果**：✅ 一致性保证（数据库事务 + 缓存删除）

## 性能优化

### 1. 同步写入缓存

**当前实现**：`FindByID` 中同步写入缓存

**原因**：
- 确保缓存与数据库的一致性
- Redis Set 操作通常很快（< 1ms）
- 异步写入失败可能导致缓存不一致

**权衡**：
- ✅ 保证一致性
- ⚠️ 略微增加响应时间（通常 < 1ms）

### 2. 异步延迟删除

**当前实现**：`Update` 中异步执行延迟删除

**原因**：
- 延迟删除不阻塞业务返回
- 通过 goroutine 异步执行，不影响性能

**权衡**：
- ✅ 不阻塞业务
- ✅ 处理并发场景
- ⚠️ 可能短暂存在旧数据（500ms内）

## 监控建议

### 1. 缓存命中率

**指标**：
- 缓存命中次数 / 总查询次数
- 目标：> 80%

**实现**：
```go
// 在 FindByID 中记录
if found {
    metrics.CacheHitCounter.Inc()
} else {
    metrics.CacheMissCounter.Inc()
}
```

### 2. 缓存操作失败率

**指标**：
- 缓存操作失败次数 / 总操作次数
- 目标：< 1%

**实现**：
```go
// 记录缓存错误
if err != nil {
    metrics.CacheErrorCounter.Inc()
}
```

### 3. 数据一致性检查

**建议**：
- 定期对比缓存和数据库数据
- 发现不一致时记录告警
- 自动修复不一致数据（可选）

## 防护策略详解

### 1. 缓存穿透防护（Cache Penetration）

**问题**：查询不存在的数据（如不存在的用户ID），每次都查数据库，导致数据库压力大

**解决方案**：空值缓存

**实现**：
```go
// 查询不存在的数据时，缓存空值标记
if ent.IsNotFound(err) {
    // 缓存空值标记（__NULL__），过期时间5分钟
    r.cacheRepo.Set(ctx, cacheKey, "__NULL__", 5*time.Minute)
    return nil, errors.NotFound(...)
}

// 查询缓存时，检查是否为空值标记
if cachedValue == "__NULL__" {
    return nil, errors.NotFound(...)
}
```

**关键点**：
- ✅ 空值标记使用特殊字符串 `__NULL__`，避免与正常数据混淆
- ✅ 空值缓存过期时间较短（5分钟），避免长时间缓存不存在的数据
- ✅ 下次查询时直接返回 NotFound，不再查询数据库

**配置**：
- `userCacheNullValue = "__NULL__"` - 空值标记
- `userCacheNullExpiration = 5 * time.Minute` - 空值缓存过期时间

### 2. 缓存击穿防护（Cache Breakdown）

**问题**：热点数据过期，大量请求同时查询数据库，导致数据库压力激增

**解决方案**：分布式锁 + 等待重试

**实现流程**：
```
1. 缓存未命中
   ↓
2. 尝试获取分布式锁
   ├─ 获取成功 → 查询数据库 → 写入缓存 → 释放锁
   └─ 获取失败 → 持续重试查询缓存（等待其他协程完成）
      ├─ 缓存命中 → 返回数据
      └─ 达到最大重试次数 → 降级到数据库查询（记录告警）
```

**关键点**：
- ✅ 使用分布式锁（Redis SET NX），只允许一个协程查询数据库
- ✅ 获取锁失败的协程持续重试查询缓存，等待持有锁的协程完成
- ✅ 重试间隔 100ms，最大重试 20 次（总共约 2 秒）
- ✅ 如果达到最大重试仍未命中，降级到数据库查询（记录告警）

**配置**：
- `userCacheLockExpiration = 10 * time.Second` - 锁过期时间
- `userCacheWaitMaxRetries = 20` - 等待重试最大次数
- `userCacheWaitRetryInterval = 100 * time.Millisecond` - 等待重试间隔

**并发场景示例**：
```
时间线：
T1: 请求A 查询缓存（未命中）
T2: 请求A 获取锁（成功）
T3: 请求B 查询缓存（未命中）
T4: 请求B 获取锁（失败，请求A持有）
T5: 请求B 等待并重试查询缓存（未命中）
T6: 请求A 查询数据库（完成）
T7: 请求A 写入缓存（完成）
T8: 请求A 释放锁（完成）
T9: 请求B 重试查询缓存（命中）✅
```

### 3. 缓存雪崩防护（Cache Avalanche）

**问题**：大量缓存同时过期，导致数据库压力激增

**解决方案**：
- 设置随机过期时间（如：1小时 ± 10分钟）
- 使用分布式锁，确保只有一个请求查询数据库（已在防击穿中实现）

**建议实现**（当前未实现，可后续优化）：
```go
// 设置随机过期时间，避免大量缓存同时过期
expiration := userCacheExpiration + time.Duration(rand.Intn(600))*time.Second
```

### 4. 热点数据保护

**场景**：某个用户数据被频繁访问

**解决方案**：
- 延长热点数据的过期时间
- 使用本地缓存（如 freecache）作为二级缓存

## 最佳实践

### 1. 缓存预热

**场景**：系统启动时，预加载热点数据到缓存

**实现**：
```go
// 在服务启动时
func (r *userRepo) WarmupCache(ctx context.Context, userIDs []int64) {
    for _, id := range userIDs {
        _, _ = r.FindByID(ctx, id)  // 触发缓存写入
    }
}
```

### 2. 监控告警

**建议监控指标**：
- 缓存穿透率：空值缓存命中次数 / 总查询次数
- 缓存击穿率：获取锁失败的次数 / 总查询次数
- 等待超时率：达到最大重试次数的次数 / 总查询次数

**告警阈值**：
- 缓存穿透率 > 10%：可能存在恶意查询或数据问题
- 等待超时率 > 1%：数据库查询时间过长或锁过期时间设置不合理

## 总结

### 一致性保证

✅ **最终一致性**：通过 Cache-Aside + 延迟双删保证

### 性能优化

✅ **读操作**：缓存命中时直接返回，减少数据库压力
✅ **写操作**：延迟双删异步执行，不阻塞业务

### 可靠性

✅ **降级策略**：缓存故障时自动降级到数据库查询
✅ **错误处理**：缓存操作失败不影响核心业务

### 可维护性

✅ **代码清晰**：每个操作都有详细的注释说明
✅ **日志完善**：关键操作都有日志记录，便于排查问题

## 参考

- [Cache-Aside Pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside)
- [最终一致性](https://en.wikipedia.org/wiki/Eventual_consistency)
- [Redis 最佳实践](https://redis.io/docs/manual/patterns/)

